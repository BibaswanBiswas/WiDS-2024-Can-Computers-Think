{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BibaswanBiswas/WiDS-2024-Can-Computers-Think/blob/main/Week%201/work_on_bandits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQKK-nUqlPHd"
      },
      "source": [
        "# Bandit Problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bandits"
      ],
      "metadata": {
        "id": "C8I8eEStljmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmfaY8JOlPHe"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from bandits import Bandit\n",
        "import random\n",
        "# Include your imports here, if any are used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "class Bandit:\n",
        "    def __init__(self, mean=0, stddev=1):\n",
        "        self.__mean = mean\n",
        "        self.__stddev = stddev\n",
        "\n",
        "    '''This method simulates pulling the lever of the bandit and returns the reward'''\n",
        "    def pullLever(self):\n",
        "        return np.random.normal(self.__mean, self.__stddev)"
      ],
      "metadata": {
        "id": "YNRZ3EA7lns9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mduyf5wBlPHf"
      },
      "source": [
        "A list of ten bandit objects initialized in the list..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr7kR-GilPHf"
      },
      "outputs": [],
      "source": [
        "bandits = [Bandit(random.random()*4-2) for _ in range(10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOz2-wSplPHf",
        "outputId": "cdc32f74-8f16-4c1e-bc98-302e231f1b04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04364432528747145"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bandits[0].pullLever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQe8IGU3lPHg"
      },
      "source": [
        "## Greedy algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weI7DpgulPHg"
      },
      "outputs": [],
      "source": [
        "def run_greedy(k):\n",
        "  n=0\n",
        "  q=[0,0,0,0,0,0,0,0,0,0]\n",
        "  tot_rew=0\n",
        "  rew = {i: [] for i in range(k)}\n",
        "  for j in range(0,k):\n",
        "    m=max(q)\n",
        "    i=q.index(m)\n",
        "    R=bandits[i].pullLever()\n",
        "    q[i]=(n*q[i]+R)/(n+1)\n",
        "    n+=1\n",
        "    rew[i].append(R)\n",
        "    tot_rew+=R\n",
        "    plt.scatter(j+1,tot_rew/(j+1))\n",
        "  print(q)\n",
        "  for i in range(0,k):\n",
        "    if rew[i]:\n",
        "      print(\"Rewards for bandit \",i,\"is \",rew[i])\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWt2NUGClPHg"
      },
      "source": [
        "Plot the cumulative average of rewards as the number of iterations increases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY9MZr1-lPHg"
      },
      "outputs": [],
      "source": [
        "run_greedy(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ2vr6FClPHg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oToAjFvlPHg"
      },
      "source": [
        "## $\\epsilon$-greedy Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sW5wbEZlPHg"
      },
      "outputs": [],
      "source": [
        "def run_epsilon_greedy_(p,e):\n",
        "  n=0\n",
        "  q=[0,0,0,0,0,0,0,0,0,0]\n",
        "  tot_rew=0\n",
        "  rew = {i: [] for i in range(10)}\n",
        "  for j in range(0,p):\n",
        "    a=[0,1,2,3,4,5,6,7,8,9]\n",
        "    w=[e/9]*10\n",
        "    i=q.index(max(q))\n",
        "    w[i]=1-e\n",
        "    m=random.choices(a,weights=w,k=1)\n",
        "    R=bandits[m[0]].pullLever()\n",
        "    q[m[0]]=(n*q[m[0]]+R)/(n+1)\n",
        "    n+=1\n",
        "    rew[m[0]].append(R)\n",
        "    tot_rew+=R\n",
        "    plt.scatter(j+1,tot_rew/(j+1))\n",
        "  print(q)\n",
        "  for x in range(0,10):\n",
        "    if rew[x]:\n",
        "      print(\"Rewards for bandit \",x,\"is \",rew[x])\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4H6Jz4wlPHg"
      },
      "source": [
        "Plot the cumulative average of rewards as the number of iterations increases but for various values of $\\epsilon$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvmkABkylPHg"
      },
      "outputs": [],
      "source": [
        "def run_epsilon_greedy(p,e,f):\n",
        "  n=0\n",
        "  q=[0,0,0,0,0,0,0,0,0,0]\n",
        "  q1=[0]*10\n",
        "  tot_rew=0\n",
        "  tot_rew1=0\n",
        "  rew = {i: [] for i in range(10)}\n",
        "  for j in range(0,p):\n",
        "    a=[0,1,2,3,4,5,6,7,8,9]\n",
        "    w=[e/9]*10\n",
        "    w1=[f/9]*10\n",
        "    i=q.index(max(q))\n",
        "    i1=q1.index(max(q1))\n",
        "    w[i]=1-e\n",
        "    w1[i1]=1-f\n",
        "    m=random.choices(a,weights=w,k=1)\n",
        "    m1=random.choices(a,weights=w1,k=1)\n",
        "    R=bandits[m[0]].pullLever()\n",
        "    R1=bandits[m1[0]].pullLever()\n",
        "    q[m[0]]=(n*q[m[0]]+R)/(n+1)\n",
        "    q1[m1[0]]=(n*q1[m1[0]]+R1)/(n+1)\n",
        "    n+=1\n",
        "    rew[m[0]].append(R)\n",
        "    tot_rew+=R\n",
        "    tot_rew1+=R1\n",
        "    plt.scatter(j+1,tot_rew/(j+1),color='blue')\n",
        "    plt.scatter(j+1,tot_rew1/(j+1),color='red')\n",
        "  print(q)\n",
        "  print(q1)\n",
        "  for x in range(0,10):\n",
        "    if rew[x]:\n",
        "      print(\"Rewards for bandit \",x,\"is \",rew[x])\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTyulAwZlPHg"
      },
      "outputs": [],
      "source": [
        "run_epsilon_greedy(1000,0.01,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFOsL9pOlPHg"
      },
      "source": [
        "## Finding the optimal $\\epsilon$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32DfeYQKlPHh"
      },
      "source": [
        "Run the $\\epsilon$-greedy algorithm for 1000 iterations and find the optimal $\\epsilon$ value by plotting the cumulative average of rewards for various values of $\\epsilon$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xORmLnlelPHh"
      },
      "outputs": [],
      "source": [
        "def run_epsilon_greed(p):\n",
        "  plt.xlim(0,0.1)\n",
        "  plt.ylim(0,2)\n",
        "  e=0.1\n",
        "  eps=[]\n",
        "  val=[]\n",
        "  while e>0:\n",
        "    n=0\n",
        "    #color_rgb=(255*(1-e),0,255*e)\n",
        "    q=[0,0,0,0,0,0,0,0,0,0]\n",
        "    tot_rew=0\n",
        "    av=[]\n",
        "    rew = {i: [] for i in range(10)}\n",
        "    for j in range(0,p):\n",
        "      a=[0,1,2,3,4,5,6,7,8,9]\n",
        "      w=[e/9]*10\n",
        "      i=q.index(max(q))\n",
        "      w[i]=1-e\n",
        "      m=random.choices(a,weights=w,k=1)\n",
        "      R=bandits[m[0]].pullLever()\n",
        "      q[m[0]]=(n*q[m[0]]+R)/(n+1)\n",
        "      n+=1\n",
        "      rew[m[0]].append(R)\n",
        "      tot_rew+=R\n",
        "      av.append(tot_rew/(j+1))\n",
        "    eps.append(e)\n",
        "    val.append(tot_rew/p)\n",
        "    #plt.plot(av,label=str(e))\n",
        "    #plt.legend()\n",
        "    e-=0.001\n",
        "  plt.plot(eps,val,color='blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQgyVjHQlPHh"
      },
      "outputs": [],
      "source": [
        "run_epsilon_greed(100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac7VwL9BlPHh"
      },
      "source": [
        "## Optimistic Initial Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjsnwJ0jlPHh"
      },
      "outputs": [],
      "source": [
        "def run_optimistic_greedy_optimality(p,e):\n",
        "  n=1\n",
        "  q=[10]*10\n",
        "  q1=[0]*10\n",
        "  q2=[0]*10\n",
        "  tot=0.0\n",
        "  tot1=0.0\n",
        "  tot2=0.0\n",
        "  avg=[]\n",
        "  avg1=[]\n",
        "  avg2=[]\n",
        "  while n<=p:\n",
        "    r=bandits[q.index(max(q))].pullLever()\n",
        "    r1=bandits[q1.index(max(q1))].pullLever()\n",
        "    q1[q1.index(max(q1))]=(r1+n*q1[q1.index(max(q1))])/(n+1)\n",
        "    q[q.index(max(q))]=(r+n*q[q.index(max(q))])/(n+1)\n",
        "    tot+=r\n",
        "    tot1+=r1\n",
        "    avg.append(q[q.index(max(q))]-10/(n))\n",
        "    avg1.append(q1[q1.index(max(q1))]/n)\n",
        "    a=[0,1,2,3,4,5,6,7,8,9]\n",
        "    w2=[e/9]*10\n",
        "    i2=q2.index(max(q2))\n",
        "    w2[i2]=1-e\n",
        "    m2=random.choices(a,weights=w2,k=1)\n",
        "    R2=bandits[m2[0]].pullLever()\n",
        "    q2[m2[0]]=(n*q2[m2[0]]+R2)/(n+1)\n",
        "    tot2+=R2\n",
        "    avg2.append(q2[m2[0]])\n",
        "    n+=1\n",
        "  plt.plot(avg,color='blue',label='optimistic')\n",
        "  plt.plot(avg1,color='red',label='non-optimistic greedy')\n",
        "  plt.plot(avg2,color='green',label='epsilon greedy')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWi6rVqwlPHh"
      },
      "source": [
        "Plot the cumulative average of rewards as the number of iterations increases for an optimistic greedy of $Q_1 = 10$ and a non-optimistic $\\epsilon = 0.1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiTshDyhlPHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEgPxzW0lPHh"
      },
      "outputs": [],
      "source": [
        "run_optimistic_greedy_optimality(1000,0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBYY4HnlPHh"
      },
      "source": [
        "## Optional - Upper Confidence Bound (UCB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qux5DcJ2lPHh"
      },
      "outputs": [],
      "source": [
        "def run_ucb(c):\n",
        "    # TODO: Implement the UCB algorithm here\n",
        "    # Return the reward from the bandits in a list\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1YY2lJElPHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCmldTGvlPHh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}